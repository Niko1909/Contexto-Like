{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niko1909/Contexto-Like/blob/main/contexto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H19TSU5UgCZw",
        "outputId": "3cb6969e-3cb0-482f-972a-8a0fa3286c7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import string\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "from scipy import spatial\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer as wnl\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iq4Jrti_h7U1"
      },
      "outputs": [],
      "source": [
        "data = open('/content/glove.6B.50d.txt', 'r') # 50-dim GloVe word vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUWW4zmQj_gA",
        "outputId": "3465a6a1-a36e-4a14-e56f-005aca85c71d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 0.418 0.24968 -0.41242 0.1217 0.34527 -0.044457 -0.49688 -0.17862 -0.00066023 -0.6566 0.27843 -0\n"
          ]
        }
      ],
      "source": [
        "print(data.read(100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SOml-4vGkROG"
      },
      "outputs": [],
      "source": [
        "# build and clean embeddings (only take lemmatized words, no punctuation in word, no numbers in word)\n",
        "embeddings = {}\n",
        "for word in data:\n",
        "  word_vec = word.split()\n",
        "  if wnl().lemmatize(word_vec[0]) == word_vec[0] and all(char not in word_vec[0] for char in string.punctuation + '0123456789'):\n",
        "    embeddings[word_vec[0]] = np.asarray(word_vec[1:], dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# identify bad data (wrong shape)\n",
        "for key, val in embeddings.items():\n",
        "  if val.shape != (50,):\n",
        "    print(key)"
      ],
      "metadata": {
        "id": "IjPXQ7Awsjx0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQW-CFCeoUL4",
        "outputId": "ae009035-4129-4956-d0a5-9df3ead4a0ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "307535"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPat06NYn65B",
        "outputId": "cef32407-9277-4429-cb35-7e8a3b176318"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "embeddings['a'].shape == (50,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rZgtQXYfrZej"
      },
      "outputs": [],
      "source": [
        "def contexto(word, similarity, num_words=15):\n",
        "  \"\"\"\n",
        "  Prints the top num_words most similar words to the word inputted, using one of\n",
        "  three vector similarity metrics.\n",
        "\n",
        "  word: the term that the other words similarities are ranked on\n",
        "  similarity: the similarity metric to use: one of dot product, euclidean\n",
        "  distance, or cosine similarity\n",
        "  num_words: the number of similar words to show in the ranking\n",
        "  \"\"\"\n",
        "  lem_word = wnl().lemmatize(word)\n",
        "  if lem_word not in embeddings.keys():\n",
        "    print(f'{lem_word} does not have an embedding')\n",
        "    return\n",
        "  if num_words > len(embeddings):\n",
        "    print(f'num_words is greater than the number of embeddings! choose a num_words <= {len(embeddings)}')\n",
        "    return\n",
        "\n",
        "  if similarity == 'dot':\n",
        "    sorted_words = sorted(embeddings.keys(), reverse=True, key=lambda word1: np.dot(embeddings[word1], embeddings[word]))\n",
        "  elif similarity == 'euclidean':\n",
        "    sorted_words = sorted(embeddings.keys(), key=lambda word1: spatial.distance.euclidean(embeddings[word1], embeddings[word]))\n",
        "  elif similarity == 'cosine':\n",
        "    sorted_words = sorted(embeddings.keys(), reverse=True, key=lambda word1: np.dot(embeddings[word1], embeddings[word])/(norm(embeddings[word1])*norm(embeddings[word])))\n",
        "  else:\n",
        "    print(f'{similarity} is not one of dot, euclidean, or cosine')\n",
        "    return\n",
        "\n",
        "  print(f'The top {num_words} most similar words to {lem_word}:')\n",
        "  for i in range(1, num_words+1):\n",
        "    print(f'{i}. {sorted_words[i]}')\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWSvf_9MsWOS",
        "outputId": "fa041325-f8ec-43ff-9307-aa437869b19c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the does not have an embedding\n"
          ]
        }
      ],
      "source": [
        "contexto('the', 'euclidean')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contexto('a', 'euclidean', 1000000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JGoZMkrx2ZF",
        "outputId": "0c07bb4a-9a36-46cd-c8db-0d4d8d0a32a1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_words is greater than the number of embeddings! choose a num_words <= 307535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyijpDpiuD8w",
        "outputId": "0dffd9a0-1e2b-454b-8e17-e52d9b4bca1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top 15 most similar words to bicycle:\n",
            "1. bike\n",
            "2. motorcycle\n",
            "3. cart\n",
            "4. motorbike\n",
            "5. riding\n",
            "6. skateboard\n",
            "7. tractor\n",
            "8. taxi\n",
            "9. driving\n",
            "10. wheel\n",
            "11. wagon\n",
            "12. motorized\n",
            "13. cab\n",
            "14. snowmobile\n",
            "15. sled\n"
          ]
        }
      ],
      "source": [
        "contexto('bicycle', 'euclidean', 15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duF6KWQRw6aK",
        "outputId": "76901e42-28ff-4e29-db0d-35d40e3e5428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top 15 most similar words to bicycle:\n",
            "1. bike\n",
            "2. motorcycle\n",
            "3. car\n",
            "4. truck\n",
            "5. driver\n",
            "6. bus\n",
            "7. wheel\n",
            "8. cart\n",
            "9. vehicle\n",
            "10. passenger\n",
            "11. motorized\n",
            "12. riding\n",
            "13. biking\n",
            "14. racing\n",
            "15. motorbike\n"
          ]
        }
      ],
      "source": [
        "contexto('bicycle', 'dot', 15)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contexto('bicycle', 'cosine', 15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW89JuS8clvZ",
        "outputId": "c27c27ec-267e-4c00-d685-473a372efd40"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top 15 most similar words to bicycle:\n",
            "1. bike\n",
            "2. motorcycle\n",
            "3. cart\n",
            "4. riding\n",
            "5. motorbike\n",
            "6. taxi\n",
            "7. tractor\n",
            "8. car\n",
            "9. skateboard\n",
            "10. wheel\n",
            "11. motorized\n",
            "12. truck\n",
            "13. driving\n",
            "14. bus\n",
            "15. wagon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# next stuff can do: visualizations (to explain why euclidean and cosine are similar and dot isn't)"
      ],
      "metadata": {
        "id": "FxMvSMW88A3P"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNmaD1jI5iQRExojsQpJLwC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}